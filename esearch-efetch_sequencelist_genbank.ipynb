{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to download sequence data from NCBI for alignment, cropping and analysis of variation between species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install package requests if you do not yet have it installed\n",
    "# only need to run this once\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the list of species we are looking for from infile\n",
    "\n",
    "from Bio import Entrez\n",
    "\n",
    "infile = 'infiles/fish_species_names.txt'              # or fish_species_names.txt or some other file\n",
    "outfile_name = 'outfiles/raw_downloads/outfile.fas'    # CHANGE THIS or it will overwrite your last outfile ******************\n",
    "locus = 'COI'                                          # or cytb or COI, etc.\n",
    "Entrez.email = ''                        # fill in your e-mail here (should be registered with NCBI)\n",
    "API_KEY = ''       # use api_key if you have one (makes it faster to search at NCBI)\n",
    "\n",
    "fish_sealprey = []\n",
    "with open(infile) as f:                                 \n",
    "    for line in f:\n",
    "        fish_sealprey.append(line.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# Read all fish species into the list\n",
    "fish_species = [line.strip() for line in open(infile)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15477', '2659', '146', '7679', '10841', '69436']\n"
     ]
    }
   ],
   "source": [
    "# search NCBI for the locus for all species\n",
    "\n",
    "# dirty but fast hack for Mac\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "acc_list = []\n",
    "for fish_species in fish_sealprey:\n",
    "    # example search term: (\"Pterostichus agonus\"[Organism] AND 16S[All Fields])\n",
    "    species_term = '\"' + fish_species + '\"[Organism] AND ' + locus +'[All Fields]'\n",
    "    search_handle = Entrez.esearch(db=\"nucleotide\", term=species_term, idtype=\"acc\", usehistory=\"y\", api_key=API_KEY)\n",
    "    record = Entrez.read(search_handle)\n",
    "    search_handle.close()\n",
    "    acc_list += (record[\"IdList\"])\n",
    "\n",
    "# print the first six accession numbers retrieved\n",
    "print(acc_list[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# show how many sequence records were retrieved\n",
    "\n",
    "print(len(acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='outfiles/raw_downloads/outfile_all_fish_COI.fas' mode='w' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "# obtain DNA sequence data for each accession number from NCBI\n",
    "\n",
    "from Bio import Entrez\n",
    "import requests\n",
    "\n",
    "outfile = open(outfile_name, 'w')\n",
    "for acc in acc_list:\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id=acc, rettype=\"fasta\", retmode=\"text\", api_key=API_KEY)\n",
    "    # print output to file only if the sequence is not longer than mitochondrial size\n",
    "    accession = handle.read()\n",
    "    if len(accession) < 30000:\n",
    "        outfile.write(accession.replace('N','').replace(' ',''))\n",
    "\n",
    "print(outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustalw2 -infile=outfiles/raw_downloads/outfile_all_fish_COI.fas\n"
     ]
    }
   ],
   "source": [
    "# produce command line for Clustalw2\n",
    "# run the command line on a windows command prompt\n",
    "\n",
    "from Bio.Align.Applications import ClustalwCommandline\n",
    "cline = ClustalwCommandline(\"clustalw2\", infile=outfile_name)\n",
    "print(cline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now manually crop the alignment (*.aln) to the segment of interest<br>\n",
    "also remove unalignable sequences<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#haplotype analysis starts here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def next_haplo_name(hh):\n",
    "    if hh < 10:\n",
    "        name = 'H0' + str(hh)\n",
    "    else: name = 'H' + str(hh)\n",
    "    return name\n",
    "\n",
    "fname = 'outfiles/cropped_alignments/harders_16Slong_cropped.aln'\n",
    "handle = open(fname)\n",
    "haplos = {} #haplos have names A, B, C etc. as keys and sequence as value\n",
    "haplo_names = [] #list of haplotype names e.g. H01\n",
    "sample_names = [] #list of sample names e.g. DH\n",
    "\n",
    "#fill the fasta outfile with haplotypes\n",
    "#and fill the lists haplo_names and sample_names\n",
    "out1 = open('outfiles/haplotype_analysis/sequence_data_haplos.fas','w')\n",
    "h = 1 #number for the first haplotype\n",
    "while True:\n",
    "    line1 = handle.readline() #the name, e.g. DH01-0001\n",
    "    if not line1: break\n",
    "    line1 = line1.strip('\\n')\n",
    "    sample = line1[11:20]\n",
    "    if sample not in sample_names: #check if sample seen before, if not, add it\n",
    "        sample_names.append(sample)\n",
    "    line2 = handle.readline() #the DNA sequence\n",
    "    line2 = line2.upper()#make all uppercase\n",
    "    if line2 not in haplos.values(): #fill the haplos dictionary\n",
    "        haplo_name = next_haplo_name(h)\n",
    "        haplo_names.append(haplo_name)\n",
    "        h += 1\n",
    "        haplos[haplo_name] = line2\n",
    "        line_h = '>' + haplo_name +'\\n' + line2\n",
    "        out1.write(line_h)\n",
    "handle.close()\n",
    "out1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the first csv outfile with the individuals' haplotypes\n",
    "#will use infile fname = 'sequence_data_cropped.fas' for this\n",
    "out2 = open('outfiles/haplotype_analysis/sequence_data_ind_haplos.csv','w')\n",
    "handle = open(fname)\n",
    "while True:\n",
    "    line1 = handle.readline() #the name, e.g. DH01-0001\n",
    "    if not line1: break\n",
    "    line1 = line1.strip('\\n')\n",
    "    line2 = handle.readline() #the DNA sequence\n",
    "    for k,v in haplos.items(): #look for the haplotype code\n",
    "        if v == line2:\n",
    "            line1 = line1.strip('>').split('-')\n",
    "            line1 = ','.join(line1)\n",
    "            line_i = line1 +','+ k + '\\n'\n",
    "            out2.write(line_i)\n",
    "handle.close()\n",
    "out2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill csv file (out3) with frequencies per sample\n",
    "#will use lists haplo_names and sample_names for this\n",
    "#will also use infile fname = 'sequence_data_ind_haplos.csv' for this\n",
    "#produce Arlequin infile (out4)\n",
    "handle2 = open('outfiles/haplotype_analysis/sequence_data_ind_haplos.csv')\n",
    "out3 = open('outfiles/haplotype_analysis/sequence_data_freqs.csv','w')\n",
    "out4 = open('outfiles/haplotype_analysis/sequence_data_samples.arp','w')\n",
    "print('haplotype names: ',haplo_names)\n",
    "print('sample names: ',sample_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the head to the Arlequin file\n",
    "line_arl = '[Profile]\\nTitle=\"A sample file designed to compute amova\"\\nNbSamples=' +  str(len(sample_names)) + '\\n'\\\n",
    "    'GenotypicData=0\\nLocusSeparator=NONE\\nDataType=DNA\\nCompDistMatrix=0\\n[Data]\\n'\\\n",
    "    '[[Samples]]\\n'\n",
    "out4.write(line_arl)\n",
    "freq_table = np.zeros(shape=(len(sample_names),len(haplo_names))) #array for frequency data\n",
    "freq_table.astype(int)\n",
    "#fill the first row of csv file out3\n",
    "#haplo_names\n",
    "line = ','\n",
    "for haplo_name in haplo_names:\n",
    "    line = line + haplo_name + ','\n",
    "line = line + '\\n'\n",
    "out3.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the freq_table array\n",
    "while True:\n",
    "    line1 = handle2.readline()\n",
    "    if not line1: break\n",
    "    line1 = line1.strip('\\n')\n",
    "    ind_sample = line1[10:19]\n",
    "    ind_haplo = line1[-3:]\n",
    "    ind_sample_index = sample_names.index(ind_sample)\n",
    "    ind_haplo_index = haplo_names.index(ind_haplo)\n",
    "    freq_table[ind_sample_index,ind_haplo_index] += 1\n",
    "freq_table = freq_table.astype(int)\n",
    "\n",
    "sample_sizes = np.sum(freq_table,axis=1).tolist() #list of sample sizes\n",
    "#write freq_table array to csv file out3\n",
    "#write the sample data to the Arlequin file\n",
    "for i in range(len(sample_names)):\n",
    "    line_i = sample_names[i] + ','\n",
    "    line_arl = 'SampleName=\"' + sample_names[i] + '\"\\nSampleSize=' +\\\n",
    "        str(sample_sizes[i]) + '\\nSampleData={\\n'\n",
    "    for j in range(len(haplo_names)):\n",
    "        line_i = line_i + str(freq_table[i,j]) +','\n",
    "        line_arl = line_arl + str(haplo_names[j]) + ' ' + str(freq_table[i,j]) + ' ' +\\\n",
    "            haplos[haplo_names[j]]\n",
    "    line_i = line_i + '\\n'\n",
    "    line_arl = line_arl + '}\\n'\n",
    "    out3.write(line_i)\n",
    "    out4.write(line_arl)\n",
    "#write the footer (structure) to the Arlequin file\n",
    "line_arl = '[[Structure]]\\nStructureName=\"none\"\\nNbGroups=1\\nIndividualLevel=0\\n\\\n",
    "    Group={\\n'\n",
    "for k in sample_names:\n",
    "    line_arl = line_arl + '\"' + k + '\"\\n'\n",
    "line_arl = line_arl + '}\\n'\n",
    "out4.write(line_arl)\n",
    "\n",
    "handle2.close()\n",
    "out3.close()\n",
    "out4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
